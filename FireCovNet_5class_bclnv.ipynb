{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()\n",
    "tf.test.is_built_with_cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import argparse\n",
    "from keras.preprocessing import image\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pandas as pd\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Conv2D,BatchNormalization, LeakyReLU, ZeroPadding2D,MaxPooling2D\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, MaxPool2D,  \\\n",
    "    Dropout, Dense, Input, concatenate,      \\\n",
    "    GlobalAveragePooling2D, AveragePooling2D,\\\n",
    "    Flatten\n",
    "from keras import backend as K \n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n",
    "import math \n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
    "from keras.regularizers import l1 , l2\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_auc_score, classification_report, roc_curve\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, KFold\n",
    "from imutils import paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covid_path = list(paths.list_images('...'))\n",
    "data1 = []\n",
    "labels1 = []\n",
    "for imagePath in covid_path:\n",
    "    label = 'Covid'\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # update the data and labels lists, respectively\n",
    "    data1.append(image)\n",
    "    labels1.append(label)\n",
    "print('Covid:', len(labels1))\n",
    "\n",
    "normal_path = list(paths.list_images('...'))\n",
    "data2 = []\n",
    "labels2 = []\n",
    "for imagePath in normal_path:\n",
    "    label = 'Normal'\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # update the data and labels lists, respectively\n",
    "    data2.append(image)\n",
    "    labels2.append(label)\n",
    "print('Normal:', len(labels2))\n",
    "\n",
    "viral_path = list(paths.list_images('...'))\n",
    "data3 = []\n",
    "labels3 = []\n",
    "for imagePath in viral_path:\n",
    "    label = 'Viral Pneumonia'\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # update the data and labels lists, respectively\n",
    "    data3.append(image)\n",
    "    labels3.append(label)\n",
    "print('Viral Pneumonia:', len(labels3))\n",
    "\n",
    "\n",
    "bacteria_path = list(paths.list_images('...'))\n",
    "data4 = []\n",
    "labels4 = []\n",
    "for imagePath in bacteria_path:\n",
    "    label = 'Bacterial Pneumonia'\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # update the data and labels lists, respectively\n",
    "    data4.append(image)\n",
    "    labels4.append(label)\n",
    "print('Bacterial Pneumonia:', len(labels4))\n",
    "\n",
    "\n",
    "lung_opacity_path = list(paths.list_images('...'))\n",
    "data5 = []\n",
    "labels5 = []\n",
    "for imagePath in lung_opacity_path:\n",
    "    label = 'Lung Opacity'\n",
    "    # load the image, swap color channels, and resize it to be a fixed\n",
    "    # 224x224 pixels while ignoring aspect ratio\n",
    "    image = cv2.imread(imagePath)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = cv2.resize(image, (224, 224))\n",
    "    # update the data and labels lists, respectively\n",
    "    data5.append(image)\n",
    "    labels5.append(label)\n",
    "print('Lung Opacity:', len(labels5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "def shuffle_data(x, y):\n",
    "  tmp = list(zip(x, y)) \n",
    "  random.shuffle(tmp)\n",
    "  x, y = zip(*tmp)\n",
    "  x, y = list(x), list(y)\n",
    "  del(tmp)\n",
    "  return x, y\n",
    "data1, labels1 = shuffle_data(data1, labels1)\n",
    "data2, labels2 = shuffle_data(data2, labels2)\n",
    "data3, labels3 = shuffle_data(data3, labels3)\n",
    "data4, labels4 = shuffle_data(data4, labels4)\n",
    "data5, labels5 = shuffle_data(data5, labels5)\n",
    "\n",
    "total_data = data1 + data3 + data2 + data5 + data4\n",
    "total_labels = labels1 + labels3 + labels2 + labels5 + labels4\n",
    "print('Total data:', len(total_data))\n",
    "print('Total labels:', len(total_labels))\n",
    "total_data, total_labels = shuffle_data(total_data, total_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(total_data) / 255.0\n",
    "label = np.array(total_labels)\n",
    "# encode class values as integers\n",
    "lb = LabelEncoder()\n",
    "lb.fit(label)\n",
    "print(label[18])\n",
    "label = lb.transform(label)\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "label = np_utils.to_categorical(label)\n",
    "print(label[18])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(cm,\n",
    "                          target_names,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=None,\n",
    "                          normalize=True):\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import itertools\n",
    "\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "\n",
    "    if cmap is None:\n",
    "        cmap = plt.get_cmap('Blues')\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "\n",
    "    if target_names is not None:\n",
    "        tick_marks = np.arange(len(target_names))\n",
    "        plt.xticks(tick_marks, target_names, rotation=45)\n",
    "        plt.yticks(tick_marks, target_names)\n",
    "\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "\n",
    "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        if normalize:\n",
    "            plt.text(j, i, \"{:0.4f}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "        else:\n",
    "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.grid(False)\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label'.format(accuracy, misclass))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#my functions\n",
    "def conv_block (x,nf,kernel_size):\n",
    "  #conv layer with BN and LeakyReLU\n",
    "  x = Conv2D(nf, kernel_size, padding='same', strides=(1,1), activation=None)(x)\n",
    "  x = BatchNormalization(trainable=True)(x)\n",
    "  x = LeakyReLU(alpha=0.1)(x)\n",
    "  return x\n",
    "\n",
    "\n",
    "def maxpooling(x):\n",
    "  x= MaxPooling2D((2,2), strides=(2,2))(x)\n",
    "  return x\n",
    "\n",
    "def fire_conv(x,nf):\n",
    "    x = conv_block (x,nf//2,(3,3))\n",
    "    x = maxpooling(x)\n",
    "    x = conv_block (x,nf//4,(1,1))\n",
    "    x1 = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x1 = conv_block (x1,nf,(3,3))\n",
    "    x2 = ZeroPadding2D(padding=(1, 1))(x)\n",
    "    x2 = conv_block (x2,nf,(1,1))\n",
    "    x = keras.layers.concatenate([x1, x2], axis = 3)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FireCovNet\n",
    "\n",
    "def create_model(reg=0.0001, opt='Adam'):\n",
    "    inputs = Input(shape=(224, 224, 3))\n",
    "    x = Sequential()\n",
    "    x = conv_block(inputs, 8,(3,3))\n",
    "    x = maxpooling(x)\n",
    "    x = fire_conv(x, 32)\n",
    "    x = fire_conv(x, 64)\n",
    "    x = fire_conv(x, 128)\n",
    "    x = fire_conv(x, 256)\n",
    "    x = Conv2D(5, (1,1), padding='same', strides=(1,1), activation='relu',kernel_regularizer=l2(reg), bias_regularizer=l2(reg))(x)\n",
    "    x = BatchNormalization(trainable=True)(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(5, activation='softmax', name='predictions')(x)\n",
    "    model = Model(inputs, x)\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=opt , metrics=['accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(filepath='my-model-{val_accuracy:.2f}.hdf5',monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)\n",
    "lr_callback = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize W&B run for experiment tracking\n",
    "import wandb\n",
    "from wandb.keras import WandbCallback\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training FirecovNet using 5fold cross validation\n",
    "\n",
    "fold_no = 1\n",
    "batch_size = 8\n",
    "epochs = 50\n",
    "class_no=5\n",
    "\n",
    "acc_per_fold = []\n",
    "loss_per_fold = []\n",
    "cm_per_fold = []\n",
    "\n",
    "# Define the K-fold Cross Validator\n",
    "kfold = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "for train, test in kfold.split(data, label):\n",
    "    keras.backend.clear_session()\n",
    "    model = create_model()\n",
    "    wandb.init(project=\"firecovnet\", entity=\"hassanlou\",job_type='train', name=f'fold_{fold_no}_mine(bclnv)_{class_no}')\n",
    "    callbacks = [WandbCallback(), lr_callback, checkpoint]\n",
    "    history = model.fit(data[train],label[train], batch_size=8, epochs=50, verbose=1, validation_split=0.1 , callbacks=callbacks)\n",
    "    model.save(f'my_model_fold_{fold_no}.h5')\n",
    "    # Evaluate the model with the metrics we defined earlier  \n",
    "    print(\"[INFO] evaluating network...\")\n",
    "    (loss, accuracy) = model.evaluate(data[test], label[test], batch_size=8, verbose=1)\n",
    "    print('Test loss:', loss)\n",
    "    print('Test accuracy:', accuracy*100)\n",
    "    wandb.log({'Test loss': loss, 'Test accuracy': accuracy})\n",
    "    acc_per_fold.append(accuracy* 100)\n",
    "    loss_per_fold.append(loss)\n",
    "    print(len(label[test]))\n",
    "    print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {loss}; {model.metrics_names[1]} of {accuracy*100}%')\n",
    "  \n",
    "    predIdxs = model.predict(data[test], batch_size=8)\n",
    "    predIdxs = np.argmax(predIdxs, axis=1)\n",
    "    print(classification_report(label[test].argmax(axis=1), predIdxs, target_names=lb.classes_))\n",
    "    cm = confusion_matrix(label[test].argmax(axis=1), predIdxs)\n",
    "    wandb.log({'confusion matrix': cm})\n",
    "    print(cm)\n",
    "    cm_per_fold.append(cm)\n",
    "    wandb.join()\n",
    "    fold_no += 1\n",
    "    \n",
    "\n",
    "# == Provide average scores ==\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Score per fold')\n",
    "for i in range(0, len(acc_per_fold)):\n",
    "  print('------------------------------------------------------------------------')\n",
    "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "  keras.backend.clear_session()\n",
    "print('------------------------------------------------------------------------')\n",
    "print('Average scores for all folds:')\n",
    "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "cm_total= cm_per_fold[0]+cm_per_fold[1]+cm_per_fold[2]+cm_per_fold[3]+cm_per_fold[4]\n",
    "\n",
    "print('------------------------------------------------------------------------')\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm           = cm_total, \n",
    "                      normalize    = False,\n",
    "                      target_names = ['Bacterial Pneumonia','Covid','Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
    "                      title        = \"Overlapped Confusion Matrix\")\n",
    "plot_confusion_matrix(cm           = cm_total, \n",
    "                      normalize    = True,\n",
    "                      target_names = ['Bacterial Pneumonia','Covid','Lung Opacity', 'Normal', 'Viral Pneumonia'],\n",
    "                      title        = \"Overlapped Confusion Matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "snn_pred = model.predict(data[test], batch_size=8, verbose=1) \n",
    "snn_predicted = np.argmax(snn_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "n_classes = 5\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "plt.figure(figsize = (8,6))\n",
    "#plt.figure(2)\n",
    "plt.xlim(-0.008, 0.2)\n",
    "plt.ylim(0.7, 1.005)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(label[test][:, i], snn_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label[test].ravel(), snn_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "# plotting   \n",
    "# \n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-average ROC curve (area = {0:0.2f})'\n",
    "''.format(roc_auc[\"micro\"]),color='deeppink', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], label='macro-average ROC curve (area = {0:0.2f})'\n",
    "''.format(roc_auc[\"macro\"]),color='navy', linestyle=':', linewidth=2) \n",
    "plt.plot(fpr[0], tpr[0], linestyle='-',color='orange', label='ROC curve of Bacterial Pneumonia (area = {1:0.2f})'\n",
    "''.format(0, roc_auc[0]))\n",
    "plt.plot(fpr[1], tpr[1], linestyle='-',color='green', label='ROC curve of Covid-19 (area = {1:0.2f})'\n",
    "''.format(1, roc_auc[1]))\n",
    "plt.plot(fpr[2], tpr[2], linestyle='-',color='yellow', label='ROC curve of Lung Opacity (area = {1:0.2f})'\n",
    "''.format(2, roc_auc[2]))\n",
    "plt.plot(fpr[3], tpr[3], linestyle='-',color='blue', label='ROC curve of Normal (area = {1:0.2f})'\n",
    "''.format(3, roc_auc[3]))\n",
    "plt.plot(fpr[4], tpr[4], linestyle='-',color='red', label='ROC curve of Viral Pneumonia (area = {1:0.2f})'\n",
    "''.format(4, roc_auc[4]))\n",
    "\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.grid(True)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('Multiclass ROC',dpi=300);  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "n_classes = 5\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Plot linewidth.\n",
    "lw = 2\n",
    "plt.figure(figsize = (8,6))\n",
    "#plt.figure(2)\n",
    "plt.xlim(-0.02, 1.02)\n",
    "plt.ylim(0, 1.02)\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(label[test][:, i], snn_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(label[test].ravel(), snn_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "# plotting   \n",
    "# \n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-average ROC curve (area = {0:0.2f})'\n",
    "''.format(roc_auc[\"micro\"]),color='deeppink', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"], label='macro-average ROC curve (area = {0:0.2f})'\n",
    "''.format(roc_auc[\"macro\"]),color='navy', linestyle=':', linewidth=2) \n",
    "plt.plot(fpr[0], tpr[0], linestyle='-',color='orange', label='ROC curve of Bacterial Pneumonia (area = {1:0.2f})'\n",
    "''.format(0, roc_auc[0]))\n",
    "plt.plot(fpr[1], tpr[1], linestyle='-',color='green', label='ROC curve of Covid-19 (area = {1:0.2f})'\n",
    "''.format(1, roc_auc[1]))\n",
    "plt.plot(fpr[2], tpr[2], linestyle='-',color='yellow', label='ROC curve of Lung Opacity (area = {1:0.2f})'\n",
    "''.format(2, roc_auc[2]))\n",
    "plt.plot(fpr[3], tpr[3], linestyle='-',color='blue', label='ROC curve of Normal (area = {1:0.2f})'\n",
    "''.format(3, roc_auc[3]))\n",
    "plt.plot(fpr[4], tpr[4], linestyle='-',color='red', label='ROC curve of Viral Pneumonia (area = {1:0.2f})'\n",
    "''.format(4, roc_auc[4]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.grid(True)\n",
    "plt.title('ROC curve')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive rate')\n",
    "plt.legend(loc='best')\n",
    "plt.savefig('Multiclass ROC',dpi=300);  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_array(img, data_format='channels_last', dtype='float32'):\n",
    "    \"\"\"Converts a PIL Image instance to a Numpy array.\n",
    "    # Arguments\n",
    "        img: PIL Image instance.\n",
    "        data_format: Image data format,\n",
    "            either \"channels_first\" or \"channels_last\".\n",
    "        dtype: Dtype to use for the returned array.\n",
    "    # Returns\n",
    "        A 3D Numpy array.\n",
    "    # Raises\n",
    "        ValueError: if invalid `img` or `data_format` is passed.\n",
    "    \"\"\"\n",
    "    if data_format not in {'channels_first', 'channels_last'}:\n",
    "        raise ValueError('Unknown data_format: %s' % data_format)\n",
    "    # Numpy array x has format (height, width, channel)\n",
    "    # or (channel, height, width)\n",
    "    # but original PIL image has format (width, height, channel)\n",
    "    x = np.asarray(img, dtype=dtype)\n",
    "    if len(x.shape) == 3:\n",
    "        if data_format == 'channels_first':\n",
    "            x = x.transpose(2, 0, 1)\n",
    "    elif len(x.shape) == 2:\n",
    "        if data_format == 'channels_first':\n",
    "            x = x.reshape((1, x.shape[0], x.shape[1]))\n",
    "        else:\n",
    "            x = x.reshape((x.shape[0], x.shape[1], 1))\n",
    "    else:\n",
    "        raise ValueError('Unsupported image shape: %s' % (x.shape,))\n",
    "    return x"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "3219535c4a1cd5461f9263558cd6393def54f1ce54c564c28eb2b6716e4d9d7b"
  },
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
